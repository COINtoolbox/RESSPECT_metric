{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of posterior samples\n",
    "\n",
    "_Kara Ponder (SLAC-->?), Emille Ishida (Clermont-Ferrand), Alex Malz (GCCL@RUB)_\n",
    "\n",
    "plagiarized from `Combination_plots.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import glob\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import scipy.stats as sps\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kara's plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes = {'SLSN': 'o',\n",
    "              'SNIax': 's',\n",
    "              'SNII': 'd',\n",
    "              'SNIbc': 'X',\n",
    "              'SLSN': 'v',\n",
    "              'AGN': '^',\n",
    "              'TDE': '<',\n",
    "              'KN': '>',\n",
    "              'CART': 't'}\n",
    "\n",
    "alpha_dict = dict()\n",
    "alpha_dict['wfd']= {          'perfect3000': 1, \n",
    "                              'fiducial3000': 1, \n",
    "                              'random3000': 1,\n",
    "                              '75SNIa25SNII': 1, \n",
    "                              '90SNIa10SNII': 0.9,\n",
    "                              '95SNIa5SNII': 0.75,\n",
    "                              '98SNIa2SNII': 0.6,\n",
    "                              '99SNIa1SNII': 0.45,\n",
    "                              '90SNIa10SNIbc': 0.9,\n",
    "                              '95SNIa5SNIbc': 0.75,\n",
    "                              '98SNIa2SNIbc': 0.6,\n",
    "                              '99SNIa1SNIbc': 0.45,\n",
    "                              '75SNIa25SNIax': 1,\n",
    "                              '90SNIa10SNIax': 0.9,\n",
    "                              '95SNIa5SNIax': 0.75,\n",
    "                              '98SNIa2SNIax': 0.6,\n",
    "                              '99SNIa1SNIax': 0.45,\n",
    "                              '98SNIa2CART': 0.6,\n",
    "                              '99SNIa1CART': 0.45,\n",
    "                              '98SNIa2SLSN': 0.6,\n",
    "                              '99SNIa1SLSN': 0.45\n",
    "                  }\n",
    "alpha_dict['ddf'] = {\n",
    "                          'perfect3000': 1, \n",
    "                          'fiducial3000': 1, \n",
    "                          'random3000': 1,\n",
    "                          '90SNIa10SNII': 0.9,\n",
    "                          '95SNIa5SNII': 0.75,\n",
    "                          '98SNIa2SNII': 0.6,\n",
    "                          '99SNIa1SNII': 0.45,\n",
    "                          '95SNIa5SNIbc': 0.75,\n",
    "                          '98SNIa2SNIbc': 0.6,\n",
    "                          '99SNIa1SNIbc': 0.45,\n",
    "                          '90SNIa10SNIax': 0.9,\n",
    "                          '95SNIa5SNIax': 0.75,\n",
    "                          '98SNIa2SNIax': 0.6,\n",
    "                          '99SNIa1SNIax': 0.45}\n",
    "\n",
    "def make_remap_dict_perc(file_extension):\n",
    "    if 'wfd' == file_extension:\n",
    "        remap_dict = OrderedDict({\n",
    "                              'perfect3000': 'Perfect', \n",
    "                              'fiducial3000': 'Fiducial', \n",
    "                              'random3000': 'Random',\n",
    "                              '75SNIa25SNII': 'SN-II 25 %', \n",
    "                              '90SNIa10SNII': 'SN-II 10 %',\n",
    "                              '95SNIa5SNII': 'SN-II 5 %',\n",
    "                              '98SNIa2SNII': 'SN-II 2 %',\n",
    "                              '99SNIa1SNII': 'SN-II 1 %',\n",
    "                              '90SNIa10SNIbc': 'SN-Ibc 10 %',\n",
    "                              '95SNIa5SNIbc': 'SN-Ibc 5 %',\n",
    "                              '98SNIa2SNIbc': 'SN-Ibc 2 %',\n",
    "                              '99SNIa1SNIbc': 'SN-Ibc 1 %',\n",
    "                              '75SNIa25SNIax': 'SN-Iax 25 %',\n",
    "                              '90SNIa10SNIax': 'SN-Iax 10 %',\n",
    "                              '95SNIa5SNIax': 'SN-Iax 5 %',\n",
    "                              '98SNIa2SNIax': 'SN-Iax 2 %',\n",
    "                              '99SNIa1SNIax': 'SN-Iax 1 %',\n",
    "                              '98SNIa2CART': 'CART 2 %',\n",
    "                              '99SNIa1CART': 'CART 1 %',\n",
    "                              '98SNIa2SLSN': 'SLSN 2 %',\n",
    "                              '99SNIa1SLSN': 'SLSN 1 %'\n",
    "                  })\n",
    "    else:\n",
    "        remap_dict = OrderedDict({\n",
    "                          'perfect3000': 'Perfect', \n",
    "                          'fiducial3000': 'Fiducial', \n",
    "                          'random3000': 'Random',\n",
    "                          '90SNIa10SNII': 'SN-II 10 %',\n",
    "                          '95SNIa5SNII': 'SN-II 5 %',\n",
    "                          '98SNIa2SNII': 'SN-II 2 %',\n",
    "                          '99SNIa1SNII': 'SN-II 1 %',\n",
    "                          '95SNIa5SNIbc': 'SN-Ibc 5 %',\n",
    "                          '98SNIa2SNIbc': 'SN-Ibc 2 %',\n",
    "                          '99SNIa1SNIbc': 'SN-Ibc 1 %',\n",
    "                          '90SNIa10SNIax': 'SN-Iax 10 %',\n",
    "                          '95SNIa5SNIax': 'SN-Iax 5 %',\n",
    "                          '98SNIa2SNIax': 'SN-Iax 2 %',\n",
    "                          '99SNIa1SNIax': 'SN-Iax 1 %',\n",
    "              })\n",
    "    return(remap_dict)\n",
    "\n",
    "a_file = open(\"colors.pkl\", \"rb\")\n",
    "contaminant_colors = pickle.load(a_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDF summary on the COIN server:\n",
    "file_extensions = {'ddf': 'DDF', \n",
    "                   'wfd': 'WFD'\n",
    "                  }\n",
    "ktot = 1\n",
    "nobjs = '3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases(field, k='', nobjs=3000):\n",
    "    if k == '':\n",
    "        k = '0'\n",
    "    dirname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'+field+'/results/v'+k+'/' + str(nobjs) + '/samples/'\n",
    "    cases = os.listdir(dirname)\n",
    "    \n",
    "    if '.ipynb_checkpoints' in cases:\n",
    "        cases.remove('.ipynb_checkpoints')\n",
    "\n",
    "    return(cases, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases, dirnames = {}, {}\n",
    "for file_extension in file_extensions:\n",
    "    cases[file_extension], dirnames[file_extension] = get_cases(file_extensions[file_extension], k=str(ktot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remap_dict(file_extension):\n",
    "    if 'WFD' == file_extension:\n",
    "        remap_dict = OrderedDict({\n",
    "                              'perfect3000': 'Perfect', \n",
    "                              'fiducial3000': 'Fiducial', \n",
    "                              'random3000': 'Random',\n",
    "                              '75SNIa25SNII': 'SN-II 25', \n",
    "                              '90SNIa10SNII': 'SN-II 10',\n",
    "                              '95SNIa5SNII': 'SN-II 5',\n",
    "                              '98SNIa2SNII': 'SN-II 2',\n",
    "                              '99SNIa1SNII': 'SN-II 1',\n",
    "                              '90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                              '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                              '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                              '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                              '75SNIa25SNIax': 'SN-Iax 25',\n",
    "                              '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                              '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                              '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                              '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                              '98SNIa2CART': 'CART 2',\n",
    "                              '99SNIa1CART': 'CART 1',\n",
    "                              '98SNIa2SLSN': 'SLSN 2',\n",
    "                              '99SNIa1SLSN': 'SLSN 1'\n",
    "                  })\n",
    "    else:\n",
    "        remap_dict = OrderedDict({\n",
    "                          'perfect3000': 'Perfect', \n",
    "                          'fiducial3000': 'Fiducial', \n",
    "                          'random3000': 'Random',\n",
    "                          '72SNIa28SNII': 'SN-II 28',\n",
    "                          '75SNIa25SNII': 'SN-II 25', \n",
    "                          '90SNIa10SNII': 'SN-II 10',\n",
    "                          '95SNIa5SNII': 'SN-II 5',\n",
    "                          '98SNIa2SNII': 'SN-II 2',\n",
    "                          '99SNIa1SNII': 'SN-II 1',\n",
    "                          '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                          '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                          '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                          '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                          '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                          '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                          '99SNIa1SNIax': 'SN-Iax 1',\n",
    "              })\n",
    "    return(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_dicts = {}\n",
    "for file_extension in file_extensions:\n",
    "    thing = make_remap_dict(file_extension)\n",
    "    tempdict = {}\n",
    "    for case in cases[file_extension]:\n",
    "        if case[:-4] in thing.keys():\n",
    "            tempdict[case[:-4]] = thing[case[:-4]]\n",
    "    \n",
    "    remap_dicts[file_extension] = tempdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the percent contaminated to the colormap.\n",
    "## size corresponds to remap_dict\n",
    "def make_color_nums(file_extension):\n",
    "\n",
    "    if file_extension == 'wfd':\n",
    "        color_num = np.array([1, 1, 1,                     # Special\n",
    "                              28, 25, 10, 5, 2, 1,        # II\n",
    "                              10, 5, 2, 1,                # Ibc\n",
    "                              25, 10, 5, 2, 1,            # Iax\n",
    "                              2, 1,                       # CART\n",
    "                              2, 1                       # SLSN\n",
    "                          ])                   \n",
    "    else:\n",
    "        color_num = np.array([1, 1, 1,                  # Special\n",
    "                              25, 10, 5, 2, 1,          # II\n",
    "                              5, 2, 1,                  # Ibc\n",
    "                              10, 5, 2, 1,              # Iax\n",
    "                              2,1,                      # SLSN\n",
    "                              2,1                       # CART\n",
    "                          ]) \n",
    "    return(color_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_nums = {}\n",
    "for file_extension in file_extensions.keys():\n",
    "    color_nums[file_extension] = make_color_nums(file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=30) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the curve(s)\n",
    "\n",
    "KDE for each set of posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2. * sys.float_info.min\n",
    "\n",
    "def safe_log(arr, threshold=eps):\n",
    "    \"\"\"\n",
    "    Takes the natural logarithm of an array that might contain zeros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, float\n",
    "        array of values to be logged\n",
    "    threshold: float, optional\n",
    "        small, positive value to replace zeros and negative numbers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logged: ndarray\n",
    "        logged values, with small value replacing un-loggable values\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr[arr < threshold] = threshold\n",
    "    logged = np.log(arr)\n",
    "    return logged\n",
    "\n",
    "def make_grid(x, y, x_ngrid=100, y_ngrid=100):\n",
    "    x_min = x.min()#-1.2\n",
    "    x_max = x.max()#-0.8\n",
    "    y_min = y.min()#0.2\n",
    "    y_max = y.max()#0.4\n",
    "\n",
    "    x_grid, y_grid = np.mgrid[x_min:x_max:x_ngrid*1.j, y_min:y_max:y_ngrid*1.j]\n",
    "    x_vec, y_vec = x_grid[:, 0], y_grid[0, :]\n",
    "    dx = (x_max - x_min) / (x_ngrid - 1)\n",
    "    dy = (y_max - y_min) / (y_ngrid - 1)\n",
    "\n",
    "    return(((x_min, y_min), (x_max, y_max)), (x_grid, y_grid), (x_vec, y_vec), (dx, dy))\n",
    "\n",
    "def make_kde(Xgrid, Ygrid, Xsamps, Ysamps, to_log=False, save=None, one_d=True):\n",
    "    if not one_d:\n",
    "        positions = np.vstack([Xgrid.ravel(), Ygrid.ravel()])\n",
    "        values = np.vstack([Xsamps, Ysamps])\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = np.reshape(kernel(positions).T, Xgrid.shape)\n",
    "    else:\n",
    "        positions = Xgrid.T[0]\n",
    "        values = Xsamps\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = kernel(positions)\n",
    "    \n",
    "    if to_log:\n",
    "        return safe_log(Z)\n",
    "    else:\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posteriors(field, k, casename, nsn, withlowz=True):\n",
    "    \n",
    "    if 'perfect' in casename or 'random' in casename or 'fiducial' in casename:\n",
    "        if str(nsn) not in casename:\n",
    "            case = casename + str(nsn)\n",
    "        else:\n",
    "            case = casename\n",
    "    else:\n",
    "        case = casename\n",
    "\n",
    "    filename = 'chains_'+case\n",
    "\n",
    "    if withlowz:\n",
    "        filename = filename+'_lowz_withbias'\n",
    "    path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/' + file_extensions[field] + \\\n",
    "               '/results/v' + str(k) + '/' + str(nsn) + '/posteriors/pkl/'\n",
    "\n",
    "    ext = '.pkl'\n",
    "\n",
    "    samppathname = path_pre+filename+ext\n",
    "\n",
    "    if ext == '.csv.gz':\n",
    "        with gzip.open(samppathname) as sampfile:\n",
    "            sampdata = pd.read_csv(sampfile)\n",
    "    elif ext == '.pkl':\n",
    "        with open(samppathname, 'rb') as sampfile:\n",
    "            sampdata = pkl.load(sampfile)\n",
    "\n",
    "    return([sampdata['w'], sampdata['om']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cases = ['perfect', 'random', 'fiducial']\n",
    "kmin = 0\n",
    "samp_sizes = [1500, 3000, 6000]\n",
    "ngrid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in null_cases:\n",
    "        outdata[field][casename] = np.empty((ktot, len(samp_sizes), 2, ngrid))\n",
    "        for k in range(kmin, ktot, 1):\n",
    "            for i, nsn in enumerate(samp_sizes):\n",
    "                kpass = k\n",
    "                [w_comp, Omm_comp] = get_posteriors(field, kpass, casename, nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "                comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "                (w_grid, Omm_grid) = comp_grids\n",
    "                kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "                outdata[field][casename][k][i] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('default_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in cases[field]:\n",
    "        outdata[field][casename[:-4]] = np.empty((2, ngrid))\n",
    "        k = '0'\n",
    "        nsn = '3000'\n",
    "        [w_comp, Omm_comp] = get_posteriors(field, k, casename[:-4], nsn, withlowz=True)\n",
    "        comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "        (w_grid, Omm_grid) = comp_grids\n",
    "        kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "        outdata[field][casename[:-4]] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('testcase_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "def_styles = {'1500': ':', '3000': '-', '6000': '--'}\n",
    "\n",
    "\n",
    "with open('default_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 7))    \n",
    "for j, field in enumerate(file_extensions):\n",
    "    for casename in null_cases:\n",
    "        ax[j].scatter([0], [0], label=casename, color=def_colors[casename])\n",
    "        for i, nsn in enumerate(samp_sizes):\n",
    "            for k in range(ktot-1, ktot):\n",
    "                w_grid, kde_comp = indata[field][casename][k][i]\n",
    "                ax[j].plot(w_grid, np.exp(kde_comp), \n",
    "                linestyle=def_styles[str(nsn)], color=def_colors[casename], alpha=0.8, linewidth=1.25)\n",
    "    for nsn in samp_sizes:\n",
    "        ax[j].plot([0], [0], label=str(nsn), \n",
    "                 linestyle=def_styles[str(nsn)], color='tab:green', alpha=1., linewidth=1.25) \n",
    "    ax[j].set_yticks([10, 15, 20])\n",
    "    ax[j].set_yticklabels([10, 15, 20], fontsize=14)\n",
    "    ax[j].set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "    ax[j].vlines(-1., ax[j].get_ylim()[0], ax[j].get_ylim()[1], color='gray', alpha=0.5)\n",
    "\n",
    "    if j == 0:\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "        ax[j].set_xticks([])\n",
    "\n",
    "    if j == 1:\n",
    "        #ax[j].set_xticks([-1.6, -1.4, -1.2, -1.0, -0.8])\n",
    "        #ax[j].set_xticklabels([-1.6, -1.4, -1.2, -1.0, -0.8], fontsize=14)\n",
    "        ax[j].legend(loc='upper left', fontsize=14)#, ncol=2)\n",
    "        ax[j].set_xlabel(r'$w$', fontsize=18)\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "    ax[j].set_xlim(-1.6, -0.75)\n",
    "fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, contaminants = {}, {}\n",
    "for field in file_extensions:\n",
    "    rate, contaminant = {}, {}\n",
    "    for key in remap_dicts[field]:\n",
    "        postsplit = remap_dicts[field][key].split()\n",
    "        if len(postsplit) > 1:\n",
    "            name = postsplit[0]\n",
    "            perc = float(postsplit[-1])\n",
    "\n",
    "            rate[key] = perc\n",
    "            contaminant[key] = name\n",
    "    rates[field] = rate\n",
    "    contaminants[field] = contaminant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: automate dividing into panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [0., 1., 2., 5., 7.5, 15., 50.]\n",
    "cutofflabels = ['<1%', '1%', '2%', '5%', '10%', '25%']\n",
    "\n",
    "panel_groups = {}\n",
    "for field in file_extensions:\n",
    "    panel_groups[field] = {j: [] for j in range(6)}\n",
    "\n",
    "    for i, casefn in enumerate(rates[field]):\n",
    "        casename = casefn#[:-4]\n",
    "        rate = rates[field][casename]\n",
    "        if rate > 0. and rate < 1.:\n",
    "            panel_groups[field][0].append(casename)\n",
    "        elif rate >= 1. and rate < 2.:\n",
    "            panel_groups[field][1].append(casename)\n",
    "        elif rate >= 2. and rate < 5.:\n",
    "            panel_groups[field][2].append(casename)\n",
    "        elif rate >= 5. and rate < 7.5:\n",
    "            panel_groups[field][3].append(casename)\n",
    "        elif rate >= 7.5 and rate <= 15.:\n",
    "            panel_groups[field][4].append(casename)\n",
    "        elif rate >= 15. and rate <= 50.:\n",
    "            panel_groups[field][5].append(casename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_set = set(contaminants['ddf'].values())\n",
    "\n",
    "wfd_set = set(contaminants['wfd'].values())\n",
    "all_contaminants = np.unique(np.array(list(ddf_set) + list(wfd_set)))\n",
    "\n",
    "\n",
    "color_list = OrderedDict({contaminant: plt.cm.tab10(i) for i, contaminant in enumerate(all_contaminants)})\n",
    "\n",
    "contaminant_colors = {}\n",
    "for field in file_extensions:\n",
    "    contaminant_colors[field] = {}\n",
    "    for i, contaminant in enumerate(contaminants[field]):\n",
    "        contaminant_colors[field][contaminant] = color_list[contaminants[field][contaminant]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = {}\n",
    "\n",
    "with open('testcase_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "for field in file_extensions:\n",
    "    table_loc = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'+file_extensions[field]+'/results/v'+str(3)+'/3000/summary_stats.csv'\n",
    "    \n",
    "    df = pd.read_csv(table_loc)\n",
    "    df = df.set_index('case')\n",
    "\n",
    "    fig = pylab.figure(figsize=(15, 10))\n",
    "    bigAxes = pylab.axes(frameon=False)     # hide frame\n",
    "    bigAxes.set_xticks([])                        # don't want to see any ticks on this axis\n",
    "    bigAxes.set_yticks([])\n",
    "\n",
    "    bigAxes.set_title(file_extensions[field], fontsize=20)\n",
    "    numrows=2\n",
    "    numcols=3\n",
    "\n",
    "    for i in range(len(panel_groups[field])):\n",
    "        per_panel_contaminants = [contaminants[field][panel_groups[field][i][j]] \n",
    "                                  for j in range(len(panel_groups[field][i]))]\n",
    "        uniques, unique_ind = np.unique(per_panel_contaminants, return_index=True)\n",
    "        \n",
    "        axs[i] = fig.add_subplot(numrows,numcols,i+1)\n",
    "        ax = axs[i]\n",
    "\n",
    "        stylecount = 0\n",
    "        for j, val in enumerate(unique_ind):\n",
    "            casename = panel_groups[field][i][val]\n",
    "            w_grid, kde_comp = indata[field][casename]\n",
    "            \n",
    "            if (i > 0):\n",
    "                ax.plot(w_grid, np.exp(kde_comp), color=contaminant_colors[field][casename], label=per_panel_contaminants[val])\n",
    "                \n",
    "            #ax.set_xlim(-1.2, -0.9)\n",
    "            ax.set_xlabel(r'$w$', fontsize=18)\n",
    "            #ax.set_xticks([-1.15, -1.1, -1.05, -1.0, -0.95])\n",
    "            #ax.set_xticklabels([-1.15, -1.1, -1.05,-1.0, -0.95], fontsize=16)\n",
    "                \n",
    "                \n",
    "        if i == 5:    \n",
    "            l = ax.legend(fontsize=13, loc='upper right', bbox_to_anchor=(1.02, 1.02), title=cutofflabels[i])\n",
    "        elif i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            l = ax.legend(fontsize=13, loc='upper left', bbox_to_anchor=(-0.02, 1.02), title=cutofflabels[i])\n",
    "        \n",
    "        if i > 0:\n",
    "            plt.setp(l.get_title(),fontsize=14)\n",
    "        \n",
    "        if 0 < i < 3 and field == 'ddf':\n",
    "            axs[i].set_ylim(0., 32.)\n",
    "        elif i > 2 and field == 'ddf':\n",
    "            axs[i].set_ylim(0, 45)\n",
    "        \n",
    "        if 0 < i < 3 and field == 'wfd':\n",
    "            axs[i].set_ylim(0., 25.)\n",
    "        elif i > 2 and field == 'wfd':\n",
    "            axs[i].set_ylim(0, 30)\n",
    "           \n",
    "        if i%3 == 0:\n",
    "            ax.set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "        elif i in [1,2]:\n",
    "            ax.set_ylim(axs[1].get_ylim())\n",
    "        elif i in [4,5]:\n",
    "            ax.set_ylim(axs[3].get_ylim())\n",
    "        \n",
    "    for ii in [1,2,4,5]:\n",
    "        axs[ii].set_yticks([])\n",
    "        \n",
    "    axs[0].set_yticks([0, 10, 20, 30])\n",
    "    axs[0].set_yticklabels([0, 10, 20, 30], fontsize=14)\n",
    "\n",
    "    if field == 'ddf':    \n",
    "        axs[3].set_yticks([0, 10, 20, 30,40])\n",
    "        axs[3].set_yticklabels([0, 10, 20, 30,40], fontsize=14)\n",
    "    else:    \n",
    "        axs[3].set_yticks([0, 5, 15, 25])\n",
    "        axs[3].set_yticklabels([0, 5, 15, 25], fontsize=14)\n",
    "        \n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i].vlines(-1., axs[i].get_ylim()[0], axs[i].get_ylim()[1], color='gray', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a_file = open(\"colors.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(contaminant_colors, a_file)\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "x = np.linspace(-2,0,1000)\n",
    "k = {}\n",
    "k['DDF'] = [7, 7, 7]\n",
    "k['WFD'] = [5, 5, 5]\n",
    "\n",
    "group1 = ['99SNIa1SNII', '99SNIa1SNIax', '99SNIa1SNIbc']\n",
    "group2 = ['98SNIa2SNII', '98SNIa2SNIax', '98SNIa2SNIbc']\n",
    "group3 = ['95SNIa5SNII', '95SNIa5SNIax', '95SNIa5SNIbc']\n",
    "\n",
    "data_temp = []\n",
    "\n",
    "for field in ['WFD', 'DDF']:\n",
    "    for case in group1:\n",
    "\n",
    "        fname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/DDF/results/v' + str(k[field][0]) + '/' + \\\n",
    "                '3000/posteriors/csv/chains_' + case + '_lowz_withbias.csv.gz'\n",
    "    \n",
    "    \n",
    "        remaps = make_remap_dict(field)\n",
    "        data = pd.read_csv(fname, index_col=False)\n",
    "        data['case'] = case\n",
    "        data['case_label'] = remaps[case]\n",
    "        data['field'] = field\n",
    "        data_temp.append(data)\n",
    "    \n",
    "    for case in group2:\n",
    "\n",
    "        fname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/DDF/results/v' + str(k[field][1]) + '/' + \\\n",
    "                '3000/posteriors/csv/chains_' + case + '_lowz_withbias.csv.gz'\n",
    "\n",
    "        data = pd.read_csv(fname, index_col=False)\n",
    "        data['case'] = case\n",
    "        data['case_label'] = remaps[case]\n",
    "        data['field'] = field\n",
    "        data_temp.append(data)\n",
    "\n",
    "    for case in group3:\n",
    "\n",
    "        fname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/DDF/results/v' + str(k[field][2]) + '/' + \\\n",
    "                '3000/posteriors/csv/chains_' + case + '_lowz_withbias.csv.gz'\n",
    "\n",
    "        data = pd.read_csv(fname, index_col=False)\n",
    "        data['case'] = case\n",
    "        data['case_label'] = remaps[case]\n",
    "        data['field'] = field\n",
    "        data_temp.append(data)\n",
    "\n",
    "    \n",
    "data_all = pd.concat(data_temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['case_label'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "flag = np.array([data_all2['case'].values[i] in group1 for i in range(data_all2.shape[0])])\n",
    "sns.kdeplot(\n",
    "    data=data_all2[flag], x=\"om\", y=\"w\", hue='case_label', levels=1\n",
    ")\n",
    "plt.scatter([0.3], [-1], marker='*', s=20, color='black')\n",
    "plt.xlim(0.2, 0.35)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "flag = np.array([data_all2['case'].values[i] in group2 for i in range(data_all2.shape[0])])\n",
    "sns.kdeplot(\n",
    "    data=data_all2[flag], x=\"om\", y=\"w\", hue='case_label', levels=1\n",
    ")\n",
    "plt.scatter([0.3], [-1], marker='*', s=20, color='black')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "flag = np.array([data_all2['case'].values[i] in group3 for i in range(data_all2.shape[0])])\n",
    "sns.kdeplot(\n",
    "    data=data_all2[flag], x=\"om\", y=\"w\", hue='case_label', levels=1\n",
    ")\n",
    "plt.scatter([0.3], [-1], marker='*', s=20, color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
